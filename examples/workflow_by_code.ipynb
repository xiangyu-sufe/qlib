{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/qlib/blob/main/examples/workflow_by_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Copyright (c) Microsoft Corporation.\n",
    "#  Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, site\n",
    "from pathlib import Path\n",
    "\n",
    "################################# NOTE #################################\n",
    "#  Please be aware that if colab installs the latest numpy and pyqlib  #\n",
    "#  in this cell, users should RESTART the runtime in order to run the  #\n",
    "#  following cells successfully.                                       #\n",
    "########################################################################\n",
    "\n",
    "try:\n",
    "    import qlib\n",
    "except ImportError:\n",
    "    # install qlib\n",
    "    ! pip install --upgrade numpy\n",
    "    ! pip install pyqlib\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        # The Google colab environment is a little outdated. We have to downgrade the pyyaml to make it compatible with other packages\n",
    "        ! pip install pyyaml==5.4.1\n",
    "    # reload\n",
    "    site.main()\n",
    "\n",
    "scripts_dir = Path.cwd().parent.joinpath(\"scripts\")\n",
    "if not scripts_dir.joinpath(\"get_data.py\").exists():\n",
    "    # download get_data.py script\n",
    "    scripts_dir = Path(\"~/tmp/qlib_code/scripts\").expanduser().resolve()\n",
    "    scripts_dir.mkdir(parents=True, exist_ok=True)\n",
    "    import requests\n",
    "\n",
    "    with requests.get(\"https://raw.githubusercontent.com/microsoft/qlib/main/scripts/get_data.py\", timeout=10) as resp:\n",
    "        with open(scripts_dir.joinpath(\"get_data.py\"), \"wb\") as fp:\n",
    "            fp.write(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qlib\n",
    "import pandas as pd\n",
    "from qlib.constant import REG_CN\n",
    "from qlib.utils import exists_qlib_data, init_instance_by_config\n",
    "from qlib.workflow import R\n",
    "from qlib.workflow.record_temp import SignalRecord, PortAnaRecord\n",
    "from qlib.utils import flatten_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3760863:MainThread](2025-07-31 19:55:44,632) INFO - qlib.Initialization - [config.py:420] - default_conf: client.\n",
      "[3760863:MainThread](2025-07-31 19:55:44,639) INFO - qlib.Initialization - [__init__.py:75] - qlib successfully initialized based on client settings.\n",
      "[3760863:MainThread](2025-07-31 19:55:44,641) INFO - qlib.Initialization - [__init__.py:77] - data_path={'__DEFAULT_FREQ': PosixPath('/DATA/hxy/qlib/cn_data')}\n"
     ]
    }
   ],
   "source": [
    "provider_uri = \"~/.qlib/qlib_data/cn_data\"  # target_dir\n",
    "qlib.init(provider_uri=provider_uri, region=REG_CN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage_metric(y_pred, data):\n",
    "    \n",
    "    y_true = data.get_label()\n",
    "    coverage = (y_true <= y_pred).astype(float).mean()\n",
    "    return 'coverage', coverage, True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"model\": {\n",
    "    \"class\": \"LGBModel\",\n",
    "    \"module_path\": \"qlib.contrib.model.gbdt\",\n",
    "    \"kwargs\": {\n",
    "        \"loss\": \"mse\",\n",
    "        # \"alpha\": 0.5,\n",
    "        \"colsample_bytree\": 0.8879,\n",
    "        \"learning_rate\": 0.0421,\n",
    "        \"subsample\": 0.8789,\n",
    "        \"lambda_l1\": 205.6999,\n",
    "        \"lambda_l2\": 580.9768,\n",
    "        \"max_depth\": 8,\n",
    "        \"num_leaves\": 210,\n",
    "        \"num_threads\": 20,\n",
    "    },\n",
    "},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3760863:MainThread](2025-07-31 20:04:18,512) INFO - qlib.GRU - [pytorch_gru_ts.py:61] - GRU pytorch version...\n",
      "[3760863:MainThread](2025-07-31 20:04:18,516) INFO - qlib.GRU - [pytorch_gru_ts.py:79] - GRU parameters setting:\n",
      "d_feat : 158\n",
      "hidden_size : 64\n",
      "num_layers : 2\n",
      "dropout : 0.0\n",
      "n_epochs : 40\n",
      "lr : 0.0002\n",
      "metric : loss\n",
      "batch_size : 3000\n",
      "early_stop : 10\n",
      "optimizer : adam\n",
      "loss_type : mse\n",
      "device : cuda:0\n",
      "n_jobs : 20\n",
      "use_GPU : True\n",
      "seed : None\n",
      "[3760863:MainThread](2025-07-31 20:04:18,520) INFO - qlib.GRU - [pytorch_gru_ts.py:124] - model:\n",
      "GRUModel(\n",
      "  (rnn): GRU(158, 64, num_layers=2, batch_first=True)\n",
      "  (fc_out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "[3760863:MainThread](2025-07-31 20:04:18,522) INFO - qlib.GRU - [pytorch_gru_ts.py:125] - model size: 0.0649 MB\n"
     ]
    }
   ],
   "source": [
    "market = \"csiall\"\n",
    "benchmark = \"SH000905\"\n",
    "# 学习的参数\n",
    "learn_processors = [\n",
    "    {\"class\": \"DropnaLabel\"},\n",
    "    {\"class\": \"RobustZScoreNorm\", \"kwargs\": {\"fields_group\": \"feature\", \"clip_outlier\":True}}, # 有状态，标准化特征\n",
    "    {\"class\":\"CSZScoreNorm\", \"kwargs\": {\"fields_group\": \"label\"}} # 无状态，按天横截面标准化\n",
    "]\n",
    "# 测试集\n",
    "infer_processors = [\n",
    "    {\"class\": \"RobustZScoreNorm\", \"kwargs\": {\"fields_group\": \"feature\", \"clip_outlier\":True}},  # 使用训练集参数\n",
    "    {\"class\":\"CSZScoreNorm\", \"kwargs\": {\"fields_group\": \"label\"}} # 无状态，也要加\n",
    "]\n",
    "shared_processors = [\n",
    "    {\"class\": \"ProcessInf\", \"kwargs\": {}},\n",
    "    {\"class\": \"Fillna\", \"kwargs\":{\"fields_group\": \"feature\"}}\n",
    "]\n",
    "\n",
    "###################################\n",
    "# train model\n",
    "###################################\n",
    "data_handler_config = {\n",
    "    \"start_time\": \"2016-12-31\",\n",
    "    \"end_time\": \"2022-12-31\",\n",
    "    \"fit_start_time\": \"2016-12-31\",\n",
    "    \"fit_end_time\": \"2020-12-31\",\n",
    "    \"instruments\": market,\n",
    "    \"infer_processors\":infer_processors,\n",
    "    \"learn_processors\":learn_processors,\n",
    "}\n",
    "\n",
    "task = {\n",
    "    \"model\": {\n",
    "        \"class\": \"GRU\",\n",
    "        \"module_path\": \"qlib.contrib.model.pytorch_gru_ts\",\n",
    "        \"kwargs\": {\n",
    "            \"d_feat\": 158,\n",
    "            \"hidden_size\": 64,\n",
    "            \"num_layers\": 2,\n",
    "            \"dropout\": 0.0,\n",
    "            \"n_epochs\": 40,\n",
    "            \"lr\": 2e-4,\n",
    "            \"early_stop\": 10,\n",
    "            \"batch_size\": 3000,\n",
    "            \"metric\": \"loss\",\n",
    "            \"loss\": \"mse\",\n",
    "            \"n_jobs\": 20,\n",
    "            \"GPU\": 0,\n",
    "        },\n",
    "    },\n",
    "    \"dataset\": {\n",
    "        \"class\": \"TSDatasetH\",\n",
    "        \"module_path\": \"qlib.data.dataset\",\n",
    "        \"kwargs\": {\n",
    "            \"handler\": {\n",
    "                \"class\": \"Alpha158\",\n",
    "                \"module_path\": \"qlib.contrib.data.handler\",\n",
    "                \"kwargs\": data_handler_config,\n",
    "            },\n",
    "            \"segments\": {\n",
    "                \"train\": (\"2016-12-31\", \"2020-12-31\"),\n",
    "                \"valid\": (\"2021-01-01\", \"2021-12-31\"),\n",
    "                \"test\": (\"2022-01-01\", \"2022-12-31\"),\n",
    "            },\n",
    "            \n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# model initialization\n",
    "model = init_instance_by_config(task[\"model\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3760863:MainThread](2025-07-31 20:06:23,329) INFO - qlib.timer - [log.py:127] - Time cost: 83.636s | Loading data Done\n",
      "[3760863:MainThread](2025-07-31 20:07:10,977) INFO - qlib.timer - [log.py:127] - Time cost: 40.234s | RobustZScoreNorm Done\n",
      "[3760863:MainThread](2025-07-31 20:07:15,744) INFO - qlib.timer - [log.py:127] - Time cost: 4.758s | CSZScoreNorm Done\n",
      "[3760863:MainThread](2025-07-31 20:07:23,739) INFO - qlib.timer - [log.py:127] - Time cost: 2.865s | DropnaLabel Done\n",
      "/home/huxiangyu/.pyenv/versions/qlib/lib/python3.10/site-packages/qlib/data/dataset/processor.py:296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[self.cols] = X\n",
      "[3760863:MainThread](2025-07-31 20:07:57,345) INFO - qlib.timer - [log.py:127] - Time cost: 33.602s | RobustZScoreNorm Done\n",
      "[3760863:MainThread](2025-07-31 20:08:02,688) INFO - qlib.timer - [log.py:127] - Time cost: 5.340s | CSZScoreNorm Done\n",
      "[3760863:MainThread](2025-07-31 20:08:02,706) INFO - qlib.timer - [log.py:127] - Time cost: 99.373s | fit & process data Done\n",
      "[3760863:MainThread](2025-07-31 20:08:02,708) INFO - qlib.timer - [log.py:127] - Time cost: 183.017s | Init data Done\n"
     ]
    }
   ],
   "source": [
    "dataset = init_instance_by_config(task[\"dataset\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3760863:MainThread](2025-07-31 20:19:25,453) INFO - qlib.workflow - [exp.py:258] - Experiment 377830769695977458 starts running ...\n",
      "[3760863:MainThread](2025-07-31 20:19:25,560) INFO - qlib.workflow - [recorder.py:345] - Recorder e4c2dd9e8e0748d9ab94b3fbac523c5e starts running under Experiment 377830769695977458 ...\n",
      "[3760863:MainThread](2025-07-31 20:20:00,848) INFO - qlib.GRU - [pytorch_gru_ts.py:249] - training...\n",
      "[3760863:MainThread](2025-07-31 20:20:00,852) INFO - qlib.GRU - [pytorch_gru_ts.py:253] - Epoch0:\n",
      "[3760863:MainThread](2025-07-31 20:20:00,854) INFO - qlib.GRU - [pytorch_gru_ts.py:254] - training...\n",
      "[3760863:MainThread](2025-07-31 20:21:27,106) INFO - qlib.GRU - [pytorch_gru_ts.py:256] - evaluating...\n",
      "[3760863:MainThread](2025-07-31 20:23:25,079) INFO - qlib.GRU - [pytorch_gru_ts.py:259] - train nan, valid nan\n",
      "[3760863:MainThread](2025-07-31 20:23:25,084) INFO - qlib.GRU - [pytorch_gru_ts.py:253] - Epoch1:\n",
      "[3760863:MainThread](2025-07-31 20:23:25,087) INFO - qlib.GRU - [pytorch_gru_ts.py:254] - training...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m R\u001b[38;5;241m.\u001b[39mstart(experiment_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_model\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      3\u001b[0m     R\u001b[38;5;241m.\u001b[39mlog_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mflatten_dict(task))\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m#   feval=coverage_metric,\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m              \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     R\u001b[38;5;241m.\u001b[39msave_objects(trained_model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m      8\u001b[0m     rid \u001b[38;5;241m=\u001b[39m R\u001b[38;5;241m.\u001b[39mget_recorder()\u001b[38;5;241m.\u001b[39mid\n",
      "File \u001b[0;32m~/.pyenv/versions/qlib/lib/python3.10/site-packages/qlib/contrib/model/pytorch_gru_ts.py:255\u001b[0m, in \u001b[0;36mGRU.fit\u001b[0;34m(self, dataset, evals_result, save_path, reweighter)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, step)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 255\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluating...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    257\u001b[0m train_loss, train_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_epoch(train_loader)\n",
      "File \u001b[0;32m~/.pyenv/versions/qlib/lib/python3.10/site-packages/qlib/contrib/model/pytorch_gru_ts.py:168\u001b[0m, in \u001b[0;36mGRU.train_epoch\u001b[0;34m(self, data_loader)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mGRU_model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, weight \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[0;32m--> 168\u001b[0m     feature \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m     label \u001b[38;5;241m=\u001b[39m data[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    171\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mGRU_model(feature\u001b[38;5;241m.\u001b[39mfloat())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# start exp to train model\n",
    "with R.start(experiment_name=\"train_model\"):\n",
    "    R.log_params(**flatten_dict(task))\n",
    "    model.fit(dataset, \n",
    "            #   feval=coverage_metric,\n",
    "              )\n",
    "    R.save_objects(trained_model=model)\n",
    "    rid = R.get_recorder().id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction, backtest & analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################################\n",
    "# prediction, backtest & analysis\n",
    "###################################\n",
    "port_analysis_config = {\n",
    "    \"executor\": {\n",
    "        \"class\": \"SimulatorExecutor\",\n",
    "        \"module_path\": \"qlib.backtest.executor\",\n",
    "        \"kwargs\": {\n",
    "            \"time_per_step\": \"day\",\n",
    "            \"generate_portfolio_metrics\": True,\n",
    "        },\n",
    "    },\n",
    "    \"strategy\": {\n",
    "        \"class\": \"TopkDropoutStrategy\",\n",
    "        \"module_path\": \"qlib.contrib.strategy.signal_strategy\",\n",
    "        \"kwargs\": {\n",
    "            \"model\": model,\n",
    "            \"dataset\": dataset,\n",
    "            \"topk\": 50,\n",
    "            \"n_drop\": 5,\n",
    "        },\n",
    "    },\n",
    "    \"backtest\": {\n",
    "        \"start_time\": \"2017-01-01\",\n",
    "        \"end_time\": \"2020-08-01\",\n",
    "        \"account\": 100000000,\n",
    "        \"benchmark\": benchmark,\n",
    "        \"exchange_kwargs\": {\n",
    "            \"freq\": \"day\",\n",
    "            \"limit_threshold\": 0.095,\n",
    "            \"deal_price\": \"close\",\n",
    "            \"open_cost\": 0.0005,\n",
    "            \"close_cost\": 0.0015,\n",
    "            \"min_cost\": 5,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# backtest and analysis\n",
    "with R.start(experiment_name=\"backtest_analysis\"):\n",
    "    recorder = R.get_recorder(recorder_id=rid, experiment_name=\"train_model\")\n",
    "    model = recorder.load_object(\"trained_model\")\n",
    "\n",
    "    # prediction\n",
    "    recorder = R.get_recorder()\n",
    "    ba_rid = recorder.id\n",
    "    sr = SignalRecord(model, dataset, recorder)\n",
    "    sr.generate()\n",
    "\n",
    "    # backtest & analysis\n",
    "    par = PortAnaRecord(recorder, port_analysis_config, \"day\")\n",
    "    par.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyze graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlib.contrib.report import analysis_model, analysis_position\n",
    "from qlib.data import D\n",
    "\n",
    "recorder = R.get_recorder(recorder_id=ba_rid, experiment_name=\"backtest_analysis\")\n",
    "print(recorder)\n",
    "pred_df = recorder.load_object(\"pred.pkl\")\n",
    "report_normal_df = recorder.load_object(\"portfolio_analysis/report_normal_1day.pkl\")\n",
    "positions = recorder.load_object(\"portfolio_analysis/positions_normal_1day.pkl\")\n",
    "analysis_df = recorder.load_object(\"portfolio_analysis/port_analysis_1day.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysis position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_position.report_graph(report_normal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### risk analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_position.risk_analysis_graph(analysis_df, report_normal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysis model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = dataset.prepare(\"test\", col_set=\"label\")\n",
    "label_df.columns = [\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### score IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = pd.concat([label_df, pred_df], axis=1, sort=True).reindex(label_df.index)\n",
    "analysis_position.score_ic_graph(pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_model.model_performance_graph(pred_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qlib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
